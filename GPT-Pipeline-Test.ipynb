{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581db0f0",
   "metadata": {},
   "source": [
    "# Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244e31e",
   "metadata": {},
   "source": [
    "## Fiction (with examples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb78350",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3f606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set directory to get .env file\n",
    "%cd \"/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-Data/fiction-atlantic-master.csv')\n",
    "df.head() #grab the text column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiction examples \n",
    "examples=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-examples/Atlantic-Fiction-Examples.csv', index_col=0)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.Text.values #save the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load other dependencies \n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Atlantic'\n",
    "subtitle='Fiction'\n",
    "stim_set=title+'-'+subtitle\n",
    "seed=1 #set seed to make sure we get reproducable results \n",
    "temperature=0.1 #want a low baking temp to have little variability or creativity \n",
    "engine='gpt-3.5-turbo' #change this to use different models\n",
    "n_context=1\n",
    "cache = True   \n",
    "resume=False\n",
    "# MIDI='freq' #or 'name', 'number', 'freq'\n",
    "audience='People'\n",
    "item='Text'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#apiKey = os.environ.get('steven_key') #for stevens key \n",
    "\n",
    "apiKey = os.environ.get('angela_key') #for angelas key \n",
    "\n",
    "openai.api_key = apiKey \n",
    "\n",
    "if cache:\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(current):#(example_idxs, current_pair):\n",
    "    prompt = f\"\"\"Your task is to classify a piece of as either formal or informal. \n",
    "You will be provided with two examples of formal text and two examples of informal text. Answer only with a number: 1 if formal, and 0 if informal.  \n",
    "\n",
    "Text: {examples.Example.iloc[0]} \n",
    "Rating: {examples.Label.iloc[0]}\n",
    "    \n",
    "Text: {examples.Example.iloc[1]}\n",
    "Rating: {examples.Label.iloc[1]}\n",
    "\n",
    "Text: {examples.Example.iloc[2]}\n",
    "Rating: {examples.Label.iloc[2]}\n",
    "\n",
    "Text: {examples.Example.iloc[3]}\n",
    "Rating: {examples.Label.iloc[3]}\n",
    "    \n",
    "Text: {inputs[current]}\n",
    "Rating:\n",
    "\"\"\"\n",
    "    if n_context==0:\n",
    "        prompt = f\"\"\"Is the following piece of text formal or informal? Answer only with a number: 1 if formal, and 0 if informal Here is the text:\\n{inputs[current]}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "cache_folder = f'cache/{stim_set}'\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "def create_cache_filename():\n",
    "    filename = f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}'\n",
    "    # if args.shuffle_context_each_draw:\n",
    "    #     filename += '-shuffle'\n",
    "    return os.path.join(cache_folder, filename + '.json')\n",
    "\n",
    "if not resume:\n",
    "    visited = []\n",
    "    predicted_ratings = np.zeros((len(inputs)))\n",
    "    request_count = 0\n",
    "\n",
    "cache = {}\n",
    "\n",
    "if cache and os.path.exists(create_cache_filename()):\n",
    "    cache = json.load(open(create_cache_filename()))\n",
    "cached_keys = list(cache.keys())\n",
    "\n",
    "for idx1, bname1 in enumerate(tqdm(inputs)):\n",
    "    current = idx1\n",
    "    if current in visited and predicted_ratings[current]!=0:\n",
    "        print(f'Already visited {current}')\n",
    "        continue\n",
    "\n",
    "    visited.append(current)\n",
    "\n",
    "    key = f'{current}'\n",
    "    if key in cached_keys:\n",
    "        choices = cache[key]['choices']\n",
    "        print('Using cached choices for key', key)\n",
    "    else:\n",
    "        prompt = generate_prompt(current)#(example_idxs, current_pair)\n",
    "        response=False\n",
    "        i=0\n",
    "        while not response:\n",
    "            i+=1\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=engine,\n",
    "                    messages=[{'role':'user', 'content':prompt}],\n",
    "                    temperature=temperature,\n",
    "                    timeout=10\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Attempt {i} failed')\n",
    "                time.sleep(5)\n",
    "        choices = [dict(choice.items()) for choice in response.choices]\n",
    "\n",
    "        cache[key] = {\n",
    "            'prompt': prompt,\n",
    "            'choices': choices,\n",
    "            'created': response.created\n",
    "        }\n",
    "\n",
    "        request_count += 1\n",
    "        if cache and request_count % 5 == 0:\n",
    "            json.dump(cache, open(create_cache_filename(), 'w'))\n",
    "\n",
    "    try:\n",
    "        answer = choices[0]['message']['content'].replace('\\n', '').strip()\n",
    "        predicted_ratings[idx1] = int(answer)\n",
    "    except:\n",
    "        print('Error', cache[key])\n",
    "\n",
    "os.makedirs(f'predictions/{stim_set}', exist_ok=True)\n",
    "np.save(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', predicted_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1869e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-Data/fiction-atlantic-master.csv')\n",
    "# df_gpt4 = np.zeros((predicted_ratings.size, 3))\n",
    "# df_gpt4[np.arange(predicted_ratings.size), predicted_ratings.astype(int)] = 1\n",
    "predicted_ratings=np.load(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', allow_pickle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings # just to check it ran smoothly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71986a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_df_gpt35=pd.DataFrame(predicted_ratings, columns=['formality_ratings'])\n",
    "fiction_df_gpt35['Text']=df.Text.values\n",
    "fiction_df_gpt35['file_name']=df.file_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c31e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "output_directory = '/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/output'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "fiction_df_gpt35.to_csv(os.path.join(output_directory, f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to work on this \n",
    "\n",
    "# emotions=np.array(['yes','no'])\n",
    "df=df.reset_index()\n",
    "# one_hot = pd.get_dummies(df['human'])\n",
    "df=df.rename(columns={'human':'overall_inter_rater_reliability'})\n",
    "# df=df.join(one_hot)\n",
    "matches=np.all(df_gpt4[['offensive']]==df.reset_index(drop=True)[['offensive']],axis=1)\n",
    "np.mean(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4570ab32",
   "metadata": {},
   "source": [
    "## Non-fiction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229668e",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "    # set directory to get .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a81d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-Data/non-fiction-atlantic-master.csv')\n",
    "df.head() #grab the text column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiction examples \n",
    "examples=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-examples/Atlantic-Nonfiction-Examples.csv', index_col=0)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.Text.values #save the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load other dependencies \n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Atlantic'\n",
    "subtitle='Non-fiction'\n",
    "stim_set=title+'-'+subtitle\n",
    "seed=1\n",
    "temperature=0.1 #want a low baking temp to have little variability or creativity \n",
    "engine='gpt-3.5-turbo' #change this to use different models\n",
    "n_context=1\n",
    "cache = True   \n",
    "resume=False\n",
    "# MIDI='freq' #or 'name', 'number', 'freq'\n",
    "audience='People'\n",
    "item='Text'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#api_key = \"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\"\n",
    "#apiKey = os.environ.get('steven_key') #for stevens key \n",
    "\n",
    "apiKey = os.environ.get('angela_key') #for angelas key \n",
    "\n",
    "openai.api_key = apiKey \n",
    "\n",
    "if cache:\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(current):#(example_idxs, current_pair):\n",
    "    prompt = f\"\"\"Your task is to classify a piece of as either formal or informal. \n",
    "You will be provided with two examples of formal text and two examples of informal text. Answer only with a number: 1 if formal, and 0 if informal.  \n",
    "\n",
    "Text: {examples.Example.iloc[0]} \n",
    "Rating: {examples.Label.iloc[0]}\n",
    "    \n",
    "Text: {examples.Example.iloc[1]}\n",
    "Rating: {examples.Label.iloc[1]}\n",
    "\n",
    "Text: {examples.Example.iloc[2]}\n",
    "Rating: {examples.Label.iloc[2]}\n",
    "\n",
    "Text: {examples.Example.iloc[3]}\n",
    "Rating: {examples.Label.iloc[3]}\n",
    "    \n",
    "Text: {inputs[current]}\n",
    "Rating:\n",
    "\"\"\"\n",
    "    if n_context==0:\n",
    "        prompt = f\"\"\"Is the following piece of text formal or informal? Answer only with a number: 1 if formal, and 0 if informal Here is the text:\\n{inputs[current]}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "cache_folder = f'cache/{stim_set}'\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "def create_cache_filename():\n",
    "    filename = f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}'\n",
    "    # if args.shuffle_context_each_draw:\n",
    "    #     filename += '-shuffle'\n",
    "    return os.path.join(cache_folder, filename + '.json')\n",
    "\n",
    "if not resume:\n",
    "    visited = []\n",
    "    predicted_ratings = np.zeros((len(inputs)))\n",
    "    request_count = 0\n",
    "\n",
    "cache = {}\n",
    "\n",
    "if cache and os.path.exists(create_cache_filename()):\n",
    "    cache = json.load(open(create_cache_filename()))\n",
    "cached_keys = list(cache.keys())\n",
    "\n",
    "for idx1, bname1 in enumerate(tqdm(inputs)):\n",
    "    current = idx1\n",
    "    if current in visited and predicted_ratings[current]!=0:\n",
    "        print(f'Already visited {current}')\n",
    "        continue\n",
    "\n",
    "    visited.append(current)\n",
    "\n",
    "    key = f'{current}'\n",
    "    if key in cached_keys:\n",
    "        choices = cache[key]['choices']\n",
    "        print('Using cached choices for key', key)\n",
    "    else:\n",
    "        prompt = generate_prompt(current)#(example_idxs, current_pair)\n",
    "        response=False\n",
    "        i=0\n",
    "        while not response:\n",
    "            i+=1\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=engine,\n",
    "                    messages=[{'role':'user', 'content':prompt}],\n",
    "                    temperature=temperature,\n",
    "                    timeout=10\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Attempt {i} failed')\n",
    "                time.sleep(5)\n",
    "        choices = [dict(choice.items()) for choice in response.choices]\n",
    "\n",
    "        cache[key] = {\n",
    "            'prompt': prompt,\n",
    "            'choices': choices,\n",
    "            'created': response.created\n",
    "        }\n",
    "\n",
    "        request_count += 1\n",
    "        if cache and request_count % 5 == 0:\n",
    "            json.dump(cache, open(create_cache_filename(), 'w'))\n",
    "\n",
    "    try:\n",
    "        answer = choices[0]['message']['content'].replace('\\n', '').strip()\n",
    "        predicted_ratings[idx1] = int(answer)\n",
    "    except:\n",
    "        print('Error', cache[key])\n",
    "\n",
    "os.makedirs(f'predictions/{stim_set}', exist_ok=True)\n",
    "np.save(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-Data/non-fiction-atlantic-master.csv')\n",
    "# df_gpt4 = np.zeros((predicted_ratings.size, 3))\n",
    "# df_gpt4[np.arange(predicted_ratings.size), predicted_ratings.astype(int)] = 1\n",
    "predicted_ratings=np.load(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', allow_pickle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings # just to check it ran smoothly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfiction_df_gpt35=pd.DataFrame(predicted_ratings, columns=['formality_ratings'])\n",
    "nonfiction_df_gpt35['Text']=df.Text.values\n",
    "nonfiction_df_gpt35['file_name']=df.file_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "output_directory = '/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/output'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "fiction_df_gpt35.to_csv(os.path.join(output_directory, f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
